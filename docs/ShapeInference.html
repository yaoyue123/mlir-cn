<!DOCTYPE html>
<html  lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

      <title>Shape Inference</title>
    
          <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
          <link rel="stylesheet" href="../_static/theme.css " type="text/css" />
      
      <!-- sphinx script_files -->
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/translations.js"></script>

      
      <!-- bundled in js (rollup iife) -->
      <!-- <script src="../_static/theme-vendors.js"></script> -->
      <script src="../_static/theme.js" defer></script>
    
  <link rel="index" title="索引" href="../genindex.html" />
  <link rel="search" title="搜索" href="../search.html" /> 
  </head>

  <body>
    <div id="app">
    <div class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="../index.html" class="home-link">
    
      <span class="site-name">MLIR 中文文档</span>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">



    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            



            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">快速搜索</span>
    <div class="searchformwrapper">
      <form class="search" action="../search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="搜索" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="../index.html#mlir">欢迎使用 mlir 中文文档</a></span>
      </p>
      <ul class="">
        
          <li class="toctree-l1 ">
            
              <a href="../_index.html" class="reference internal ">开始使用MLIR</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/CreatingADialect.html" class="reference internal ">Creating a Dialect</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/DataFlowAnalysis.html" class="reference internal ">Writing DataFlow Analyses in MLIR</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/QuickstartRewrites.html" class="reference internal ">Quickstart tutorial to adding MLIR graph rewrite</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/Toy/Ch-1.html" class="reference internal ">第1章：Toy语言和AST（抽象语法树）</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/Toy/Ch-2.html" class="reference internal ">Chapter 2: Emitting Basic MLIR</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/Toy/Ch-3.html" class="reference internal ">Chapter 3: High-level Language-Specific Analysis and Transformation</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/Toy/Ch-4.html" class="reference internal ">Chapter 4: Enabling Generic Transformation with Interfaces</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/Toy/Ch-5.html" class="reference internal ">Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/Toy/Ch-6.html" class="reference internal ">Chapter 6: Lowering to LLVM and CodeGeneration</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/Toy/Ch-7.html" class="reference internal ">Chapter 7: Adding a Composite Type to Toy</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/Toy/_index.html" class="reference internal ">Toy 入门教程</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/UnderstandingTheIRStructure.html" class="reference internal ">Understanding the IR Structure</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="Tutorials/_index.html" class="reference internal ">Tutorials</a>
            

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
    
    <li>Shape Inference</li>
  </ul>
  

  <ul class="page-nav">
</ul>
  
</div>
<hr>
          <div class="content" role="main" v-pre>
            
  <section id="shape-inference">
<h1>Shape Inference<a class="headerlink" href="#shape-inference" title="此标题的永久链接">¶</a></h1>
<p>Shape inference as discussed here is considered a specific instance of type
inference for <a class="reference external" href="https://github.com/llvm/llvm-project/tree/main/mlir/include/mlir/IR/BuiltinTypes.h">ShapedType</a>. Type constraints are along (at least)
three axis: 1) elemental type, 2) rank (including static or dynamic), 3)
dimensions. While some operations have no compile time fixed shape (e.g., output
shape is dictated by data) we could still have some knowledge of
constraints/bounds in the system for that operation (e.g., the output of a
<code class="docutils literal notranslate"><span class="pre">tf.where</span></code> is at most the size of the input data). That is, there are additional
valuable constraints that could be captured even without full knowledge of the
shape.</p>
<p>Type inference is currently modelled executionally for operation creation using the
<a class="reference external" href="https://github.com/llvm/llvm-project/tree/main/mlir/include/mlir/Interfaces/InferTypeOpInterface.td"><code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></a>, while
<code class="docutils literal notranslate"><span class="pre">InferShapedTypeOpInterface</span></code> is used to implement the shape and element type
inference. The return type can often be deduced from the deduced return shape
and elemental type (queryable from <code class="docutils literal notranslate"><span class="pre">InferShapedTypeOpInterface</span></code>) and so type
inference for tensor types can be implemented with <code class="docutils literal notranslate"><span class="pre">InferShapedTypeOpInterface</span></code>.</p>
<p>[TOC]</p>
<section id="shape-functions">
<h2>Shape functions<a class="headerlink" href="#shape-functions" title="此标题的永久链接">¶</a></h2>
<p>The C++ interfaces are the base mechanism whereby shape inference is queried and
executed, but not the intended way to specify shape constraints in general.</p>
<p>Initially the shape inference will be declaratively specified using:</p>
<ul class="simple">
<li><p>Constraints on the operands of an operation directly. For example
constraining the input type to be tensor/vector elements or that the
elemental type be of a specific type (e.g., output of computing the size
of a value is of elemental type <code class="docutils literal notranslate"><span class="pre">i1</span></code>) or class (e.g., float-like).</p></li>
<li><p>Constraints across operands and results of an operation.</p>
<ul>
<li><p>For example, specifying equality constraints on type/constituents of a
type (shape and elemental type) between operands and results (e.g., the
output type of an add is the same as those of the input operands).</p></li>
</ul>
</li>
</ul>
<p>NOTE: The C++ shape functions are an intermediate step until the shape dialect
is more full-fledged, at which point the C++ functions should become the
exceptional case.</p>
</section>
<section id="testing">
<h2>Testing<a class="headerlink" href="#testing" title="此标题的永久链接">¶</a></h2>
<p>Shape inference is currently tested alongside type inference by
<code class="docutils literal notranslate"><span class="pre">TestReturnTypeDriver</span></code> in the test dialect. This driver performs two checks:</p>
<ol class="simple">
<li><p>Verification that the return types specified matches the inferred types. This
explicit check will be removed and made part of Op verification instead.</p></li>
<li><p>Test the creation of Ops without specifying the return type explicitly in
function <code class="docutils literal notranslate"><span class="pre">testCreateFunctions</span></code> by creating new binary Ops (Op classes
specified in <code class="docutils literal notranslate"><span class="pre">TestReturnTypeDriver</span></code>) using 1) all operands to
<code class="docutils literal notranslate"><span class="pre">testCreateFunctions</span></code> as both operands, and 2) using combinations of input
operands of the function.</p></li>
</ol>
</section>
<section id="shape-dialect">
<h2>Shape dialect<a class="headerlink" href="#shape-dialect" title="此标题的永久链接">¶</a></h2>
<p>This section details the shape type inference dialect (<code class="docutils literal notranslate"><span class="pre">shape</span></code>). The initial
focus will be on shape functions that describe shape functions could be used in
runtime and compiler (for constructions of ops/refinement of shapes, reification
of dynamic allocations for dialect including TF, TFLite, XLA &amp; tensor compute
dialect under discussion).</p>
<p>This will focus on the shape functions (e.g., determine the rank and dimensions
of the output shape). As shown in the shaped container type, shape will be one
of 3 components, the others being elemental type and attribute (which is
currently left open with the intention of supporting extensions such as layouts
or bounded shapes at a later point). This allows for decoupling of these:</p>
<ul class="simple">
<li><p>Not all the information is needed for all analysis;</p></li>
<li><p>Not all shape functions need to provide all the information (e.g., one could
define a base class function that only populates element type but composes
with the others);</p></li>
<li><p>It allows reusing the constraints between, say, Tensor and Memref
representation of an operation;</p></li>
</ul>
<p>An argument could be made that these are metadata function instead of shape
functions, with some considering shape and elemental types different and some considering them both as
part of shape. But <code class="docutils literal notranslate"><span class="pre">shape</span> <span class="pre">function</span></code> is IMHO descriptive and metadata can span
too large a range of potential uses/values.</p>
<section id="requirements">
<h3>Requirements<a class="headerlink" href="#requirements" title="此标题的永久链接">¶</a></h3>
<p>The requirements for the shape inference functions are determined by the
requirements of shape inference, but we believe the requirements below still
allow freedom to consider different shape inference approaches and so we do not
impose a particular shape inference approach here.</p>
<section id="shape-inference-functions">
<h4>Shape inference functions<a class="headerlink" href="#shape-inference-functions" title="此标题的永久链接">¶</a></h4>
<ul>
<li><p><strong>Expressiveness</strong> shape functions need to support programs where tensors
have shapes that are not known statically (for example, <code class="docutils literal notranslate"><span class="pre">tensor&lt;16x?xf32&gt;</span></code>
or <code class="docutils literal notranslate"><span class="pre">tensor&lt;*xf32&gt;*</span></code>);</p></li>
<li><p><strong>Shape error detection</strong> Many operations will have constraints on their
operands. If the constraints are not satisfied or cannot be determined if
satisfied statically, then a runtime check/assertion could be generated.</p>
<ul class="simple">
<li><p>This also aligns with the requirement that the shape function description
should be usable by both the compiler and runtime.</p></li>
<li><p>Shape error functions should be easy to understand, at least what
constraint of the operation is violated. This also requires that shape
function error messages should be configurable by the author of the
shape function (e.g., the author would be able to give the semantic
constraint invalidated rather the low-level check that failed).</p></li>
<li><p>The static analysis may be used to eliminate run-time checks that are
guaranteed to pass.</p>
<ul>
<li><p>Ideally all would eventually (see section
<a class="reference external" href="#inline">Inlining shape checking</a>) be elided.</p></li>
</ul>
</li>
<li><p>Only reporting errors which are guaranteed to occur at runtime. If an error is only
possible (rather than guaranteed) then we use a runtime assertion to fail and produce an error
message with the invariant violated.</p></li>
</ul>
</li>
<li><p>Shape functions usable by compiler and runtime.</p>
<ul class="simple">
<li><p>This does not mean the exact same C++ function, but rather the
description should be consumable by either.</p></li>
<li><p>Shape function description should not be constrained by either runtime
or compiler’s type system to handle types only used for analysis. That
is, these two type systems differ and both should be supported, but the
intersection of the two should not be required. As a particular example,
if a compiler only wants to differentiate exact shapes vs dynamic
shapes, then it need not consider a more generic shape lattice even
though the shape description supports it.</p></li>
</ul>
</li>
<li><p>Declarative (e.g., analyzable at compile time, possible to generate
different versions for different use cases)</p>
<ul class="simple">
<li><p>This may not strictly be a requirement, but a way to handle the former:
a declarative specification could be reused by both while avoiding a
need to map to or from a 3rd representation given these two systems
have/and will have different types.</p></li>
</ul>
</li>
<li><p>Shape inference functions are expressible at runtime</p>
<ul>
<li><p>User can define a shape function for a new operation dynamically at runtime,
this allows for vendors to describe an operation and shape function
dynamically.</p>
<p>This requirement is on the wishlist.</p>
</li>
</ul>
</li>
<li><p>Doesn’t require graph-wide shape information (e.g., only require local
information)</p>
<ul class="simple">
<li><p>Shape functions should be cheap to invoke on each kernel launch.</p></li>
<li><p>Shape function can be dictated by arguments (operands, attributes and regions)
only (e.g., same operands as the corresponding operation could be
constructed &amp; invoked with).</p></li>
<li><p>Shape information that needs higher-level/graph information should use
richer types (e.g., <code class="docutils literal notranslate"><span class="pre">TensorList&lt;F32&gt;</span></code>);</p></li>
<li><p>The function should be invocable before/while constructing an op (e.g.,
can’t rely on the op being constructed).</p></li>
</ul>
</li>
<li><p>Shape functions should be pure functions.</p></li>
<li><p>Should support functions whose type is only known dynamically (e.g.,
<code class="docutils literal notranslate"><span class="pre">read_from_file</span></code> op)</p>
<ul class="simple">
<li><p>Without needing to invoke the op (e.g., reading a file once for
determining the shape &amp; then post to be able to actually consume the
output of the file).</p></li>
</ul>
</li>
<li><p>The shape function operation dialect should be interoperable with non-shape function dialect operations.</p>
<ul>
<li><p>There may be a common set of operations that satisfy most uses (e.g., merge,
equal_type, arithmetic expressions, slice, concat, pattern matching on
attributes such as padding etc.) that will be discovered and could cover
a large percentage of the use cases. Among these there will be some
which carry extra semantic info that could be used for symbolic
constraints (e.g., checking equality of two dimensions resulting in
setting an equality constraint) and higher-order interpretation for
constraint solving.</p>
<p>It is therefore beneficial (but not required) to reuse operations,
especially as for statically known shapes, arbitrary arithmetic
computations could still be performed. This means that the computations
performed statically may or may not be supported by an arbitrary solver,
but would still be allowed.</p>
</li>
</ul>
</li>
<li><p>The shape function should be expandable such that symbolic equality and
upper bound constraints (say) could be represented and may be propagated by
shape inference.</p>
<ul class="simple">
<li><p>E.g., the shape functions may contain more information that is only
useful when used from shape inference;</p></li>
</ul>
</li>
<li><p>Shape functions are allowed to fail and report an error. The error reporting
should report the location of the operation that failed with, where
possible, a user actionable error message.</p>
<ul class="simple">
<li><p>These failures could become inlined and become runtime failures with
runtime values and error messages.</p></li>
<li><p>Reporting errors should be optional. E.g., The same function
may be used as to query validity without reporting an error.</p></li>
</ul>
</li>
</ul>
</section>
<section id="non-goals">
<h4>Non-goals<a class="headerlink" href="#non-goals" title="此标题的永久链接">¶</a></h4>
<ol class="simple">
<li><p>The shape dialect is an IR representations and not a programming language;</p>
<ul class="simple">
<li><p>While the functions should be readable, it doesn’t carry the
conveniences of a programming language. Deciding how people write these
things, e.g. a mini dsl, a C++ API that generates them, extracting them
programmatically from <code class="docutils literal notranslate"><span class="pre">SetShapeFn</span></code> calls, etc., is still TBD.</p></li>
</ul>
</li>
<li><p>Describe the shape inference approach that will use the shape functions;</p>
<ul class="simple">
<li><p>The goal is that the shape functions and the constraints one could
obtain from them are general enough that they would be useful for
various analysis. But whether we follow very simple (e.g., only fully
static information is used for shape output, unranked for everything
else) to very advance (e.g., expression trees of symbolic constants) can
be evaluated independently of this proposal and with concrete benefit
analysis.</p></li>
</ul>
</li>
<li><p>Describe the approach whereby error messages will be generated;</p>
<ul class="simple">
<li><p>While the shape functions will be able to emit errors optionally, it
will be possible to dictate when they emit an error. This enables
deciding whether or which error to emit: there have been proposals in
the literature that the iteration order for shape inference affect the
quality of the error message produced, and the shape functions do not
mandate that.</p></li>
</ul>
</li>
<li><p>Flow sensitive shape functions;</p>
<ul class="simple">
<li><p>To enable scalable/cheap shape inference, the shape functions do not
intend to provide flow sensitive information. This facility could
potentially be built as part of some higher order analysis that reuse
the shape functions/constraints due to the shape functions.</p></li>
</ul>
</li>
<li><p>All static functions are usable for dynamic/unknown shapes;</p>
<ul class="simple">
<li><p>More involved computations can be performed with statically known shapes
than what can be sensibly analyzed with unknown/symbolic variables.</p></li>
</ul>
</li>
</ol>
</section>
</section>
<section id="discussion">
<h3>Discussion<a class="headerlink" href="#discussion" title="此标题的永久链接">¶</a></h3>
<section id="inline-shape-inference-checks-inline">
<h4>Inline shape inference checks {#inline}<a class="headerlink" href="#inline-shape-inference-checks-inline" title="此标题的永久链接">¶</a></h4>
<p>Shape functions should be lowerable to runtime checks for validity. E.g. verify
as much as possible statically, but enable generating instructions to compute the
shape dynamically and or falling back to runtime checks for attributes not
verifiable at compile time. These checks inserted should ideally only check that
which could not have been verified statically.</p>
<p>These inlined calls could interfere with optimization patterns/passes (e.g.,
shape inference should not insert constructs that interfere with optimization
patterns) and so could be delayed until later (with another round of
optimizations, constant folding, CSE, etc., that should remove redundant runtime
operations).</p>
</section>
</section>
<section id="possibly-asked-questions">
<h3>Possibly Asked Questions<a class="headerlink" href="#possibly-asked-questions" title="此标题的永久链接">¶</a></h3>
<section id="what-about-ods-specifications-of-operations">
<h4>What about ODS specifications of operations?<a class="headerlink" href="#what-about-ods-specifications-of-operations" title="此标题的永久链接">¶</a></h4>
<p>In ODS we have been recording the constraints for the operands &amp; attributes of
an operation. Where these are sufficient to constrain the output shape (e.g.,
<code class="docutils literal notranslate"><span class="pre">SameOperandAndResultType</span></code> or broadcastable) we should generate the shape
function from those. Where not, an explicit shape function should be specified
(spelling TBD but currently considering using the MLIR textual form as
serialization approach).</p>
</section>
<section id="why-not-extract-the-shape-function-from-reference-implementation">
<h4>Why not extract the shape function from reference implementation?<a class="headerlink" href="#why-not-extract-the-shape-function-from-reference-implementation" title="此标题的永久链接">¶</a></h4>
<p>This could be done in future! The extracted shape function would use the shape
inference dialect, so we are starting there. Especially for operations described in a
structured way, one could autogenerate the shape function.</p>
</section>
<section id="how-in-what-language-will-the-shape-functions-be-authored">
<h4>How/in what language will the shape functions be authored?<a class="headerlink" href="#how-in-what-language-will-the-shape-functions-be-authored" title="此标题的永久链接">¶</a></h4>
<p>TBD. open to many approaches and suggestions, starting on the IR produced by
whatever language is the priority of this proposal.</p>
</section>
<section id="what-shape-inference-approach-is-being-suggested-here">
<h4>What shape inference approach is being suggested here?<a class="headerlink" href="#what-shape-inference-approach-is-being-suggested-here" title="此标题的永久链接">¶</a></h4>
<p>None. There are multiple different shape inference approaches that we could
layer on top of these. From the most basic (always return unranked), to more
useful (return fixed shape for constant inputs/arguments) to the more advanced
(create logical conjunctions of algebraic statements between symbolic named
values).</p>
</section>
</section>
<section id="open-points">
<h3>Open points<a class="headerlink" href="#open-points" title="此标题的永久链接">¶</a></h3>
<ol class="simple">
<li><p>Should shape functions that produce dynamic outputs given all statically
shaped inputs be marked specially? E.g., read from file.</p></li>
</ol>
<p>TODO: Add examples here.</p>
</section>
</section>
<section id="wip-future-considerations">
<h2>WIP/Future considerations<a class="headerlink" href="#wip-future-considerations" title="此标题的永久链接">¶</a></h2>
<p>Shape functions are determined by attributes and could be arbitrarily
complicated with a wide-range of specification possibilities. Equality
relationships are common (e.g., the elemental type of the output matches the
primitive type of the inputs, both inputs have exactly the same type [primitive
type and shape]) and so these should be easy to specify. Algebraic relationships
would also be common (e.g., a concat of <code class="docutils literal notranslate"><span class="pre">[n,m]</span></code> and <code class="docutils literal notranslate"><span class="pre">[n,m]</span></code> matrix along axis 0
is <code class="docutils literal notranslate"><span class="pre">[n+n,</span> <span class="pre">m]</span></code> matrix), while some ops only have defined shapes under certain
cases (e.g., matrix multiplication of <code class="docutils literal notranslate"><span class="pre">[a,b]</span></code> and <code class="docutils literal notranslate"><span class="pre">[c,d]</span></code> is only defined if <code class="docutils literal notranslate"><span class="pre">b</span> <span class="pre">==</span> <span class="pre">c</span></code>).</p>
<p>Instead of specifying an additional mechanism to specify a shape transfer
function, the reference implementation of the operation will be used to derive
the shape function. The reference implementation is general and can support the
arbitrary computations needed to specify output shapes.</p>
</section>
</section>


          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
</ul><div class="footer" role="contentinfo">
      &#169; 版权所有 2023, yaoyue123.
    <br>
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 6.1.3 with <a href="https://github.com/schettino72/sphinx_press_theme">Press Theme</a> 0.8.0.
</div>
            </div>
          </div>
      </page>
    </div></div>
    
    
  </body>
</html>