<!DOCTYPE html>
<html  lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

      <title>Linalg OpDSL</title>
    
          <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
          <link rel="stylesheet" href="../../../_static/theme.css " type="text/css" />
      
      <!-- sphinx script_files -->
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script src="../../../_static/translations.js"></script>

      
      <!-- bundled in js (rollup iife) -->
      <!-- <script src="../../../_static/theme-vendors.js"></script> -->
      <script src="../../../_static/theme.js" defer></script>
    
  <link rel="index" title="索引" href="../../../genindex.html" />
  <link rel="search" title="搜索" href="../../../search.html" /> 
  </head>

  <body>
    <div id="app">
    <div class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="../../../index.html" class="home-link">
    
      <span class="site-name">MLIR 中文文档</span>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">



    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            



            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">快速搜索</span>
    <div class="searchformwrapper">
      <form class="search" action="../../../search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="搜索" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="../../../index.html#mlir">欢迎使用 mlir 中文文档</a></span>
      </p>
      <ul class="">
        
          <li class="toctree-l1 ">
            
              <a href="../../../_index.html" class="reference internal ">开始使用</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/CreatingADialect.html" class="reference internal ">Creating a Dialect</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/DataFlowAnalysis.html" class="reference internal ">Writing DataFlow Analyses in MLIR</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/QuickstartRewrites.html" class="reference internal ">Quickstart tutorial to adding MLIR graph rewrite</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/Toy/Ch-1.html" class="reference internal ">Chapter 1: Toy Language and AST</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/Toy/Ch-2.html" class="reference internal ">Chapter 2: Emitting Basic MLIR</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/Toy/Ch-3.html" class="reference internal ">Chapter 3: High-level Language-Specific Analysis and Transformation</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/Toy/Ch-4.html" class="reference internal ">Chapter 4: Enabling Generic Transformation with Interfaces</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/Toy/Ch-5.html" class="reference internal ">Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/Toy/Ch-6.html" class="reference internal ">Chapter 6: Lowering to LLVM and CodeGeneration</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/Toy/Ch-7.html" class="reference internal ">Chapter 7: Adding a Composite Type to Toy</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/Toy/_index.html" class="reference internal ">Toy Tutorial</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/UnderstandingTheIRStructure.html" class="reference internal ">Understanding the IR Structure</a>
            

            
          </li>

        
          <li class="toctree-l1 ">
            
              <a href="../../Tutorials/_index.html" class="reference internal ">Tutorials</a>
            

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="../../../index.html">Docs</a> &raquo;</li>
    
    <li>Linalg OpDSL</li>
  </ul>
  

  <ul class="page-nav">
</ul>
  
</div>
<hr>
          <div class="content" role="main" v-pre>
            
  <section id="linalg-opdsl">
<h1>Linalg OpDSL<a class="headerlink" href="#linalg-opdsl" title="此标题的永久链接">¶</a></h1>
<p>Python based DSL for authoring Linalg op definitions and generating
<code class="docutils literal notranslate"><span class="pre">linalg.generic</span></code> IR based on them for samples.</p>
<p>The Linalg OpDSL is a high level DSL for constructing structured op definitions
in a way that can be exported to built-in, named structured ops via
<a class="reference external" href="_index.md/#yaml-gen">YAML-based definitions</a> or used interactively to emit
corresponding <code class="docutils literal notranslate"><span class="pre">linalg.generic</span></code> IR for the composition.</p>
<section id="basic-usage">
<h2>Basic usage<a class="headerlink" href="#basic-usage" title="此标题的永久链接">¶</a></h2>
<p>The tool is bundled with the MLIR Python bindings. To use from the CMake build
tree, MLIR must be build with Python bindings enabled
(<code class="docutils literal notranslate"><span class="pre">-DMLIR_ENALBE_BINDINGS_PYTHON=ON</span></code>). Then add the <code class="docutils literal notranslate"><span class="pre">python</span></code> directory in the
build tree to your <code class="docutils literal notranslate"><span class="pre">PYTHONPATH</span></code> environment variable (i.e. <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">PYTHONPATH=$PWD/build/tools/mlir/python_packages/mlir_core</span></code>). Optionally, use an
installed MLIR package, if available, to avoid building.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dump the `core_named_ops.py` module as YAML.</span>
python<span class="w"> </span>-m<span class="w"> </span>mlir.dialects.linalg.opdsl.dump_oplib<span class="w"> </span>.ops.core_named_ops
</pre></div>
</div>
<p>Alternatively, run the <code class="docutils literal notranslate"><span class="pre">$PWD/build/bin/update_core_linalg_named_ops.sh</span></code> script,
which is available after building the <code class="docutils literal notranslate"><span class="pre">mlir-linalg-ods-gen</span></code> target. The tool is
meant for use during both development and runtime, but not as a build tool of
the core compiler: in order to export static named op definitions to be built as
part of the compiler, the corresponding Linalg dialect YAML file must be updated
and reviewed. TODO: Develop a script to automate op updates to these files.</p>
</section>
<section id="language-guide">
<h2>Language Guide<a class="headerlink" href="#language-guide" title="此标题的永久链接">¶</a></h2>
<p>The language presented here is loosely inspired from the
<a class="reference external" href="https://arxiv.org/pdf/1802.04730.pdf">Tensor Comprehensions</a> work, adapted to
represent linalg structured ops.</p>
<p>This tool is new and rapidly evolving. For language examples, refer to the
built-in ops in the <code class="docutils literal notranslate"><span class="pre">mlir.tools.linalg_opdsl.ops</span></code> package
(<code class="docutils literal notranslate"><span class="pre">lib/Bindings/Python/mlir/tools/linalg_opdsl/ops</span></code> in the repository).</p>
<p>Using a matmul as an example, we will decompose the language:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">T1</span> <span class="o">=</span> <span class="n">TV</span><span class="o">.</span><span class="n">T1</span>
<span class="n">T2</span> <span class="o">=</span> <span class="n">TV</span><span class="o">.</span><span class="n">T2</span>

<span class="nd">@linalg_structured_op</span>
<span class="k">def</span> <span class="nf">matmul</span><span class="p">(</span><span class="n">A</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">K</span><span class="p">),</span>
           <span class="n">B</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">N</span><span class="p">),</span>
           <span class="n">C</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Performs a matrix multiplication of two 2D inputs.</span>

<span class="sd">  Numeric casting is performed on the operands to the inner multiply, promoting</span>
<span class="sd">  them to the same data type as the accumulator/output.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">domain</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">k</span><span class="p">)</span>
  <span class="n">defines</span><span class="p">(</span><span class="n">Canonicalizer</span><span class="p">)</span>
  <span class="n">implements</span><span class="p">(</span><span class="n">ContractionOpInterface</span><span class="p">)</span>
  <span class="n">C</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="n">TypeFn</span><span class="o">.</span><span class="n">cast_signed</span><span class="p">(</span>
      <span class="n">U</span><span class="p">,</span> <span class="n">A</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">k</span><span class="p">])</span> <span class="o">*</span> <span class="n">TypeFn</span><span class="o">.</span><span class="n">cast_signed</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">B</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">n</span><span class="p">])</span>
</pre></div>
</div>
<p>Here we have a simple type polymorphic contraction that takes arguments <code class="docutils literal notranslate"><span class="pre">A</span></code> and
<code class="docutils literal notranslate"><span class="pre">B</span></code> and outputs <code class="docutils literal notranslate"><span class="pre">C</span></code>. Each is bound to a <code class="docutils literal notranslate"><span class="pre">TensorDef</span></code>, which specifies:</p>
<ul class="simple">
<li><p>The symbolic element type (<code class="docutils literal notranslate"><span class="pre">T1</span></code>, <code class="docutils literal notranslate"><span class="pre">T2</span></code>, <code class="docutils literal notranslate"><span class="pre">U</span></code> above).</p></li>
<li><p>Symbolic shape expressions with symbols that are bound globally for the op (
note that in this simple example, the shape expressions are just symbol
references, but they are permitted to be a constrained set of affine
expressions).</p></li>
<li><p>Usage (<code class="docutils literal notranslate"><span class="pre">output=True</span></code>).</p></li>
</ul>
<p>The docstring will be transferred to the op definition verbatim.</p>
<p>An explicit iteration domain dimension order can be declared for the op via
<code class="docutils literal notranslate"><span class="pre">domain(D.d0[,</span> <span class="pre">D.d1...])</span></code>.</p>
<p>Special identifying op interfaces can be declared for the op via
<code class="docutils literal notranslate"><span class="pre">implements(interface1[,</span> <span class="pre">interface2...])</span></code>.</p>
<p>Extra method definitions can be declared for the op via
<code class="docutils literal notranslate"><span class="pre">defines(definition1[,</span> <span class="pre">definition2...])</span></code>.</p>
</section>
<section id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="此标题的永久链接">¶</a></h2>
<p>Structured operations take two types of runtime parameters namely scalars and
tensors. While scalars are inputs only, a tensor may be marked as an output.
Assignment expressions index the tensor parameters to access the individual
elements, while scalars can be accessed directly.</p>
<p>The following example demonstrates the use of the two parameter types:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@linalg_structured_op</span>
<span class="k">def</span> <span class="nf">copy_and_scale</span><span class="p">(</span><span class="n">val</span><span class="o">=</span><span class="n">ScalarDef</span><span class="p">(</span><span class="n">T</span><span class="p">),</span>
                   <span class="n">I</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">K</span><span class="p">),</span>
                   <span class="n">O</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">K</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Scale the input by the scalar value and store the result&quot;&quot;&quot;</span>
  <span class="n">O</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="n">val</span>
</pre></div>
</div>
<p>The operation scales the input tensor <code class="docutils literal notranslate"><span class="pre">I</span></code> scales its elements by the value <code class="docutils literal notranslate"><span class="pre">val</span></code>
and writes the result to the output tensor <code class="docutils literal notranslate"><span class="pre">out</span></code>. The scalar <code class="docutils literal notranslate"><span class="pre">val</span></code> is bound to a
<code class="docutils literal notranslate"><span class="pre">ScalarDef</span></code>, which specifies the type of the scalar operand. The tensors are
bound to a <code class="docutils literal notranslate"><span class="pre">TensorDef</span></code> as demonstrated by the matmul example. All parameters
appear in the parameter list of the operation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">copy_and_scale</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">in_tensor</span><span class="p">,</span> <span class="n">outs</span><span class="o">=</span><span class="p">[</span><span class="n">out_tensor</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="index-attributes">
<h2>Index Attributes<a class="headerlink" href="#index-attributes" title="此标题的永久链接">¶</a></h2>
<p>Index attributes are compile-time constant parameters only accessible in index
expressions. They can be used to parameterize the access pattern of a structured
operation, for example, by setting its strides. They cannot take part in the
actual computation.</p>
<p>The following example demonstrates the use of index attributes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@linalg_structured_op</span>
<span class="k">def</span> <span class="nf">strided_copy</span><span class="p">(</span><span class="n">I</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">IH</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">IW</span><span class="p">),</span>
                 <span class="n">O</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">OH</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">OW</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                 <span class="n">strides</span><span class="o">=</span><span class="n">IndexAttrDef</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">SH</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">SW</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Copy a subset of the input tensor elements to the output tensor&quot;&quot;&quot;</span>
  <span class="n">O</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">oh</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">ow</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">oh</span> <span class="o">*</span> <span class="n">S</span><span class="o">.</span><span class="n">SH</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">ow</span> <span class="o">*</span> <span class="n">S</span><span class="o">.</span><span class="n">SW</span><span class="p">]</span>
</pre></div>
</div>
<p>The operation implements a strided copy from the input tensor <code class="docutils literal notranslate"><span class="pre">I</span></code> to the output
tensor <code class="docutils literal notranslate"><span class="pre">O</span></code>. The <code class="docutils literal notranslate"><span class="pre">strides</span></code> attribute is bound to an <code class="docutils literal notranslate"><span class="pre">IndexAttrDef</span></code>. It defines
the symbols <code class="docutils literal notranslate"><span class="pre">S.SH</span></code> and <code class="docutils literal notranslate"><span class="pre">S.SW</span></code>, which are used to index the input tensor <code class="docutils literal notranslate"><span class="pre">I</span></code>.
When instantiating the operation, the attribute is set using a named argument:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">strided_copy</span><span class="p">(</span><span class="n">in_tensor</span><span class="p">,</span> <span class="n">outs</span><span class="o">=</span><span class="p">[</span><span class="n">out_tensor</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">strides</span></code> vector elements substitute the symbols <code class="docutils literal notranslate"><span class="pre">S.SH</span></code> and <code class="docutils literal notranslate"><span class="pre">S.SW</span></code> in the
index expressions of the operation instance. If no strides are provided the
<code class="docutils literal notranslate"><span class="pre">default</span></code> vector elements are used instead.</p>
<p>Index attributes are currently limited to integer vectors and only accessible in
index expressions. An operation may have multiple attributes all of them placed
at the end of the parameter list after the output tensors.</p>
</section>
<section id="shape-only-tensors">
<h2>Shape-Only Tensors<a class="headerlink" href="#shape-only-tensors" title="此标题的永久链接">¶</a></h2>
<p>Structured operations derive the iteration space given the sizes of the input
and output tensors. Certain operations need shape-only tensors that are not
accessed and exist purely for the sake of specifying the iteration domain. An
example is the pooling operation that takes a shape-only tensor to define the
iteration space of the reduction. As shape-only tensors have no uses, the
<code class="docutils literal notranslate"><span class="pre">TensorDef</span></code> takes an additional optional <code class="docutils literal notranslate"><span class="pre">index_dims</span></code> parameter to map the shape
to index dimensions.</p>
<p>The following example demonstrates the index dimension annotation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@linalg_structured_op</span>
<span class="k">def</span> <span class="nf">pooling_poly</span><span class="p">(</span>
    <span class="n">I</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">H</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">C</span><span class="p">),</span>
    <span class="n">K</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">KH</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">KW</span><span class="p">,</span> <span class="n">index_dims</span><span class="o">=</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">kh</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">kw</span><span class="p">]),</span>
    <span class="n">O</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">OH</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">OW</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">C</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">strides</span><span class="o">=</span><span class="n">IndexAttrDef</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">SH</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">SW</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">dilations</span><span class="o">=</span><span class="n">IndexAttrDef</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">DH</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">DW</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])):</span>
  <span class="n">O</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">oh</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">ow</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">TypeFn</span><span class="o">.</span><span class="n">cast_signed</span><span class="p">(</span><span class="n">U</span><span class="p">,</span>
          <span class="n">I</span><span class="p">[</span><span class="n">D</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">oh</span> <span class="o">*</span> <span class="n">S</span><span class="o">.</span><span class="n">SH</span> <span class="o">+</span> <span class="n">D</span><span class="o">.</span><span class="n">kh</span> <span class="o">*</span> <span class="n">S</span><span class="o">.</span><span class="n">DH</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">ow</span> <span class="o">*</span> <span class="n">S</span><span class="o">.</span><span class="n">SW</span> <span class="o">+</span> <span class="n">D</span><span class="o">.</span><span class="n">kw</span> <span class="o">*</span> <span class="n">S</span><span class="o">.</span><span class="n">DW</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">c</span><span class="p">])</span>
</pre></div>
</div>
<p>The pooling operation does not access the shape-only tensor <code class="docutils literal notranslate"><span class="pre">K</span></code>. Instead, the
shapes <code class="docutils literal notranslate"><span class="pre">S.KH</span></code> and <code class="docutils literal notranslate"><span class="pre">S.KW</span></code> specify the iteration domain for the reduction
dimensions <code class="docutils literal notranslate"><span class="pre">D.kh</span></code> and <code class="docutils literal notranslate"><span class="pre">D.kw</span></code>.</p>
</section>
<section id="assignments">
<h2>Assignments<a class="headerlink" href="#assignments" title="此标题的永久链接">¶</a></h2>
<p>The bulk of language consists of assignment expressions of the form above. The
iteration dimension order is determined lexically based on the order encountered
in the expression (following operator precedence if math operators are used).
TODO: Introduce a directive to fix the dimension bindings.</p>
<p>Reduction dimensions are inferred to be any dimensions on the RHS that are not
on the LHS.</p>
<p>A number of unary and binary arithmetic functions are supported:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BinaryFn.add(a,</span> <span class="pre">b)</span></code> (also via overloading the binary <code class="docutils literal notranslate"><span class="pre">+</span></code> operator)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BinaryFn.mul(a,</span> <span class="pre">b)</span></code> (also via overloading the binary <code class="docutils literal notranslate"><span class="pre">*</span></code> operator)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BinaryFn.max_signed(a,</span> <span class="pre">b)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BinaryFn.min_signed(a,</span> <span class="pre">b)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BinaryFn.sub(a,</span> <span class="pre">b)</span></code> (also via overloading the binary <code class="docutils literal notranslate"><span class="pre">-</span></code> operator)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BinaryFn.max_unsigned(a,</span> <span class="pre">b)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BinaryFn.min_unsigned(a,</span> <span class="pre">b)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">UnaryFn.exp(a)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">UnaryFn.log(a)</span></code></p></li>
</ul>
<p>As the integer types are signless, signedness is implement by different
functions that treat integers as signed or unsigned values.</p>
<p>A subset of the arithmetic functions are supported in reductions. These
reduction functions can appear as the outermost function on the RHS:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ReduceFn.add</span></code> (also overloading the inplace <code class="docutils literal notranslate"><span class="pre">+=</span></code> on a LHS)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ReduceFn.mul</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ReduceFn.max_signed</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ReduceFn.min_signed</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ReduceFn.max_unsigned</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ReduceFn.min_unsigned</span></code></p></li>
</ul>
<p>As the integer types are signless, signedness is implement by different
functions that treat integers as signed or unsigned values.</p>
<p>Additionally, type conversion functions cast an operand to a target type:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">TypeFn.cast_signed(TypeVar,</span> <span class="pre">operand)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TypeFn.cast_unsigned(TypeVar,</span> <span class="pre">operand)</span></code></p></li>
</ul>
<p>As the integer types are signless, signedness is implement by different
functions that treat integers as signed (<code class="docutils literal notranslate"><span class="pre">TypeFn.cast_signed</span></code>) or unsigned
(<code class="docutils literal notranslate"><span class="pre">TypeFn.cast_unsigned</span></code>) values.</p>
<p>There are also special forms:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">const(value)</span></code> returns a constant value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">index(dim)</span></code> returns the iteration index in the given dimension <code class="docutils literal notranslate"><span class="pre">dim</span></code>.</p></li>
</ul>
</section>
<section id="function-attributes">
<h2>Function Attributes<a class="headerlink" href="#function-attributes" title="此标题的永久链接">¶</a></h2>
<p>Function attributes are compile-time constant function parameters. They can be
used to parameterize the computation performed by a structured operation, for
example, to support signed and unsigned computations.</p>
<p>The following example demonstrates the use of function attributes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@linalg_structured_op</span>
<span class="k">def</span> <span class="nf">elemwise_binary</span><span class="p">(</span>
    <span class="n">lhs</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T1</span><span class="p">),</span>
    <span class="n">rhs</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">T2</span><span class="p">),</span>
    <span class="n">O</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">fun</span><span class="o">=</span><span class="n">BinaryFnAttrDef</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="n">BinaryFn</span><span class="o">.</span><span class="n">add</span><span class="p">),</span>
    <span class="n">cast</span><span class="o">=</span><span class="n">TypeFnAttrDef</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="n">TypeFn</span><span class="o">.</span><span class="n">cast_signed</span><span class="p">)):</span>
  <span class="n">O</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">cast</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">lhs</span><span class="p">[</span><span class="kc">None</span><span class="p">]),</span> <span class="n">cast</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">rhs</span><span class="p">[</span><span class="kc">None</span><span class="p">]))</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">fun</span></code> and <code class="docutils literal notranslate"><span class="pre">cast</span></code> function attributes by default are aliases for their
default values <code class="docutils literal notranslate"><span class="pre">BinaryFn.add</span></code> and <code class="docutils literal notranslate"><span class="pre">TypeFn.cast_signed</span></code>, respectively. When
instantiating the operation, the function attributes may be set to other
functions using optional named arguments:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">elemwise_binary</span><span class="p">(</span><span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span><span class="p">,</span> <span class="n">outs</span><span class="o">=</span><span class="p">[</span><span class="n">out_tensor</span><span class="p">],</span>
                <span class="n">fun</span><span class="o">=</span><span class="n">BinaryFn</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">cast</span><span class="o">=</span><span class="n">TypeFn</span><span class="o">.</span><span class="n">cast_unsigned</span><span class="p">)</span>
</pre></div>
</div>
<p>In the example, the <code class="docutils literal notranslate"><span class="pre">fun</span></code> and <code class="docutils literal notranslate"><span class="pre">cast</span></code> arguments adapt the body of the operation
to implement multiplication and unsigned casts instead of addition and signed
casts.</p>
<p>OpDSL supports unary, binary, and type conversion function attributes. An
operation can take multiple attributes of different kinds placed at the end of
the parameter list.</p>
</section>
<section id="types">
<h2>Types<a class="headerlink" href="#types" title="此标题的永久链接">¶</a></h2>
<p>All types in assignment expressions are late bound based on actual input and
output types of constructed ops. An exception are predefined types such as
<code class="docutils literal notranslate"><span class="pre">I32</span></code>, <code class="docutils literal notranslate"><span class="pre">I64</span></code>, <code class="docutils literal notranslate"><span class="pre">F32</span></code>, and <code class="docutils literal notranslate"><span class="pre">F64</span></code>. These hardwired types enable intermediate
computations with a type that is independent of the input and output types. For
example, parts of floating point computation may require double precision
arithmetic despite all inputs and outputs being single precision values.
Assignment expressions with no <code class="docutils literal notranslate"><span class="pre">TypeFn.cast_signed</span></code> calls will generally require
uniform types throughout and will fail to verify if violated. The presence of a
<code class="docutils literal notranslate"><span class="pre">TypeFn.cast_signed</span></code> or <code class="docutils literal notranslate"><span class="pre">TypeFn.cast_unsigned</span></code> allows for a limited form of
numeric type conversion between element types that can be derived from inputs
and outputs (and in the future, attributes). <code class="docutils literal notranslate"><span class="pre">TypeFn.cast_signed</span></code> calls with a
<code class="docutils literal notranslate"><span class="pre">TypeVar</span></code> first argument are emitted as <code class="docutils literal notranslate"><span class="pre">type_fn</span></code> primitives in the YAML
definition.</p>
<p>Casting will perform <code class="docutils literal notranslate"><span class="pre">int&lt;-&gt;float</span></code> and <code class="docutils literal notranslate"><span class="pre">index-&gt;int</span></code> type conversions and will
perform any necessary extension or truncation within the type family. The
integer types themselves are signless and signedness is implemented by
functions/operations. The <code class="docutils literal notranslate"><span class="pre">TypeFn.cast_signed</span></code> function treats all integers as
signed, while <code class="docutils literal notranslate"><span class="pre">TypeFn.cast_unsigned</span></code> treats them as unsigned.</p>
<p>The following examples illustrate the lowering of signed and unsigned functions:</p>
<ul class="simple">
<li><p>cast_signed(I32 -&gt; I64) -&gt; <code class="docutils literal notranslate"><span class="pre">arith.ExtSIOp</span></code></p></li>
<li><p>cast_signed(F32 -&gt; I32) -&gt; <code class="docutils literal notranslate"><span class="pre">arith.FPToSIOp</span></code></p></li>
<li><p>cast_unsigned(I32 -&gt; I64) -&gt; <code class="docutils literal notranslate"><span class="pre">arith.ExtUIOp</span></code></p></li>
<li><p>cast_unsigned(F32 -&gt; I32) -&gt; <code class="docutils literal notranslate"><span class="pre">arith.FPToUIOp</span></code></p></li>
<li><p>max_signed -&gt; <code class="docutils literal notranslate"><span class="pre">arith.MaxSIOp</span></code></p></li>
<li><p>max_unsinged -&gt; <code class="docutils literal notranslate"><span class="pre">arith.MaxUIOp</span></code></p></li>
</ul>
<p>Not all functions are applicable for all numeric types, and on mismatch, op
verification will fail.</p>
</section>
<section id="pointwise-computations">
<h2>Pointwise Computations<a class="headerlink" href="#pointwise-computations" title="此标题的永久链接">¶</a></h2>
<p>Pointwise computations are expressible in a rank polymorphic form that supports
arbitrary ranked operands - all of them need to have the same rank - with a
single operation definition.</p>
<p>An example for a rank polymorphic operation is <code class="docutils literal notranslate"><span class="pre">fill</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@linalg_structured_op</span>
<span class="k">def</span> <span class="nf">fill</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">ScalarDef</span><span class="p">(</span><span class="n">T1</span><span class="p">),</span>
         <span class="n">O</span><span class="o">=</span><span class="n">TensorDef</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">True</span><span class="p">)):</span>
  <span class="n">O</span><span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="n">TypeFn</span><span class="o">.</span><span class="n">cast_signed</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
<p>The operation sets the elements of the output tensor <code class="docutils literal notranslate"><span class="pre">O</span></code> to <code class="docutils literal notranslate"><span class="pre">value</span></code>. All
operands are either scalars or rank zero tensors that are accessed using the
index <code class="docutils literal notranslate"><span class="pre">None</span></code>. The operation thus performs a scalar computation that trivially
extends to a multi-dimensional pointwise computation. As a result, we may use
<code class="docutils literal notranslate"><span class="pre">fill</span></code> with arbitrary ranked output tensors:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tensor_2d</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">EmptyOp</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">f32</span><span class="p">)</span>
<span class="n">tensor_3d</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">EmptyOp</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="n">f32</span><span class="p">)</span>
<span class="n">fill</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">outs</span><span class="o">=</span><span class="p">[</span><span class="n">tensor_2d</span><span class="p">])</span>
<span class="n">fill</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">outs</span><span class="o">=</span><span class="p">[</span><span class="n">tensor_3d</span><span class="p">])</span>
</pre></div>
</div>
</section>
</section>


          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
</ul><div class="footer" role="contentinfo">
      &#169; 版权所有 2023, yaoyue123.
    <br>
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 6.1.3 with <a href="https://github.com/schettino72/sphinx_press_theme">Press Theme</a> 0.8.0.
</div>
            </div>
          </div>
      </page>
    </div></div>
    
    
  </body>
</html>